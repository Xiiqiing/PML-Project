{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cR3ul-LwiTLU",
        "olVmPkohickL",
        "HDUf_6fEihwQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##2.1 The Baseline: A site-indep model "
      ],
      "metadata": {
        "id": "aIo1n5EviHvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get sequence from BLAT_ECOLX_1_b0.5_labeled.fasta"
      ],
      "metadata": {
        "id": "cR3ul-LwiTLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ciqno19BQHB-"
      },
      "outputs": [],
      "source": [
        "# parsing the FASTA file, codes from https://colab.research.google.com/github/wouterboomsma/pml_vae_project/blob/main/protein_vae_data_processing.ipynb\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from Bio import SeqIO\n",
        "except:\n",
        "    !pip install biopython\n",
        "    from Bio import SeqIO\n",
        "    \n",
        "if not os.path.exists('BLAT_ECOLX_1_b0.5_labeled.fasta'):\n",
        "    !wget https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_1_b0.5_labeled.fasta\n",
        "        \n",
        "if not os.path.exists('BLAT_ECOLX_Ranganathan2015.csv'):\n",
        "    !wget https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_Ranganathan2015.csv\n",
        "        \n",
        "aa1_to_index = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6,\n",
        "                'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12,\n",
        "                'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18,\n",
        "                'Y': 19, 'X':20, 'Z': 21, '-': 22}\n",
        "aa1 = \"ACDEFGHIKLMNPQRSTVWYXZ-\"\n",
        "\n",
        "phyla = ['Acidobacteria', 'Actinobacteria', 'Bacteroidetes',\n",
        "         'Chloroflexi', 'Cyanobacteria', 'Deinococcus-Thermus',\n",
        "         'Firmicutes', 'Fusobacteria', 'Proteobacteria', 'Other']\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        " \n",
        "def get_baseline_data(data_filename, calc_weights=False, weights_similarity_threshold=0.8):\n",
        "    ids = []\n",
        "    labels = []\n",
        "    seqs = []\n",
        "    label_re = re.compile(r'\\[([^\\]]*)\\]')\n",
        "    for record in SeqIO.parse(data_filename, \"fasta\"):\n",
        "        ids.append(record.id)       \n",
        "        seqs.append(np.array([aa1_to_index[aa] for aa in str(record.seq).upper().replace('.', '-')]))\n",
        "        \n",
        "        label = label_re.search(record.description).group(1)\n",
        "\n",
        "        if label not in phyla:\n",
        "            label = 'Other'\n",
        "        labels.append(label)\n",
        "                \n",
        "    seqs =np.vstack(seqs)\n",
        "    labels = np.array(labels)\n",
        "    seqs_tensor = torch.from_numpy(seqs)\n",
        "\n",
        "    phyla_lookup_table, phyla_idx = np.unique(labels, return_inverse=True)\n",
        "    dataset = torch.utils.data.TensorDataset(*[seqs_tensor, torch.from_numpy(phyla_idx)])\n",
        "    \n",
        "    weights = None\n",
        "    if calc_weights is not False:\n",
        "\n",
        "        # Experiencing memory issues on colab for this code because pytorch doesn't\n",
        "        # allow one_hot directly to bool. Splitting in two and then merging.\n",
        "        # one_hot = F.one_hot(seqs_tensor.long()).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        one_hot1 = F.one_hot(seqs_tensor[:len(seqs_tensor)//2].long()).bool()\n",
        "        one_hot2 = F.one_hot(seqs_tensor[len(seqs_tensor)//2:].long()).bool()\n",
        "        one_hot = torch.cat([one_hot1, one_hot2]).to(device)\n",
        "        assert(len(seqs_tensor) == len(one_hot))\n",
        "        del one_hot1\n",
        "        del one_hot2\n",
        "        one_hot[seqs_tensor>19] = 0\n",
        "        flat_one_hot = one_hot.flatten(1)\n",
        "\n",
        "        weights = []\n",
        "        weight_batch_size = 1000\n",
        "        flat_one_hot = flat_one_hot.float()\n",
        "        for i in range(seqs_tensor.size(0) // weight_batch_size + 1):\n",
        "            x = flat_one_hot[i * weight_batch_size : (i + 1) * weight_batch_size]\n",
        "            similarities = torch.mm(x, flat_one_hot.T)\n",
        "            lengths = (seqs_tensor[i * weight_batch_size : (i + 1) * weight_batch_size] <=19).sum(1).unsqueeze(-1).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            w = 1.0 / (similarities / lengths).gt(weights_similarity_threshold).sum(1).float()\n",
        "            weights.append(w)\n",
        "            \n",
        "        weights = torch.cat(weights)\n",
        "        neff = weights.sum()\n",
        "    return seqs, labels, weights, phyla_lookup_table, phyla_idx, dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqs, labels, weights, phyla_lookup_table, phyla_idx, dataset=get_baseline_data('BLAT_ECOLX_1_b0.5_labeled.fasta',calc_weights=True)"
      ],
      "metadata": {
        "id": "5DAA_WME1XQQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "olVmPkohickL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def my_log(data):\n",
        "  if data > 0:\n",
        "    result = np.log(data)\n",
        "  else:\n",
        "    result = 0\n",
        "  return result\n",
        "\n",
        "class base1ine(object):\n",
        "    def __init__(self, pseudo_count = 1):\n",
        "        self.pseudo_count = pseudo_count\n",
        "        self.freqs = []\n",
        "\n",
        "    def get_freqs(self, seq_data):\n",
        "        for position in range(seq_data.shape[1]):\n",
        "            freq_aa_in_position = {}\n",
        "            aa_in_position = seq_data[:, position]\n",
        "            count_aa = Counter(aa_in_position)\n",
        "            num_aa = len(np.unique(aa_in_position))\n",
        "            for i in range(23):\n",
        "                freq_aa_in_position[i] = (count_aa[i] + self.pseudo_count) / (seq_data.shape[0] + num_aa * self.pseudo_count)\n",
        "            self.freqs.append(freq_aa_in_position)\n",
        "\n",
        "    def get_P_of_seqs(self, seq_data):   \n",
        "        P_of_seqs = []\n",
        "        for seq in seq_data:\n",
        "            P_of_seq= 0\n",
        "            for i, aa in enumerate(seq):\n",
        "                P_of_seq += my_log(self.freqs[i][aa])\n",
        "            P_of_seqs.append(P_of_seq)\n",
        "            P_of_seqs = np.array(P_of_seqs)\n",
        "        return P_of_seqs"
      ],
      "metadata": {
        "id": "iowkRqxfU3sY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = base1ine(pseudo_count=1)"
      ],
      "metadata": {
        "id": "USEgQHCDOlHm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Experimental data"
      ],
      "metadata": {
        "id": "HDUf_6fEihwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_experimental_data(filename, alignment_data, measurement_col_name = '2500', sequence_offset=0):\n",
        "    \n",
        "    measurement_df = pd.read_csv(filename, delimiter=',', usecols=['mutant', measurement_col_name])\n",
        "    \n",
        "    wt_sequence, wt_label = alignment_data[0]\n",
        "    \n",
        "    zero_index = None\n",
        "    \n",
        "    experimental_data = {}\n",
        "    for idx, entry in measurement_df.iterrows():\n",
        "        mutant_from, position, mutant_to = entry['mutant'][:1],int(entry['mutant'][1:-1]),entry['mutant'][-1:]  \n",
        "       \n",
        "        if zero_index is None:\n",
        "            zero_index = position\n",
        "\n",
        "        seq_position = position-zero_index+sequence_offset\n",
        "            \n",
        "        assert mutant_from == aa1[wt_sequence[seq_position]]  \n",
        "        \n",
        "        if seq_position not in experimental_data:\n",
        "            experimental_data[seq_position] = {}\n",
        "        \n",
        "        assert mutant_to not in experimental_data[seq_position]\n",
        "        \n",
        "        experimental_data[seq_position]['pos'] = seq_position\n",
        "        experimental_data[seq_position]['WT'] = mutant_from\n",
        "        experimental_data[seq_position][mutant_to] = entry[measurement_col_name]\n",
        "    \n",
        "    experimental_data = pd.DataFrame(experimental_data).transpose().set_index(['pos', 'WT'])\n",
        "    return experimental_data\n",
        "        \n",
        "experimental_data = read_experimental_data(\"BLAT_ECOLX_Ranganathan2015.csv\", dataset)"
      ],
      "metadata": {
        "id": "MpP1db0woMtm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "QcxVy9meirUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.get_freqs(seqs)"
      ],
      "metadata": {
        "id": "RbkidDPPqBLZ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "raw_sequence = [seqs[0]]\n",
        "log_P_of_wt = baseline.get_P_of_seqs(raw_sequence)\n",
        "experiment_value = []\n",
        "predicted_value = []\n",
        "for (position, mutant_from), row in experimental_data.iterrows():\n",
        "    assert aa1_to_index[mutant_from] == raw_sequence[0][position]\n",
        "    for mutant_to, exp_value in row.iteritems():\n",
        "        if mutant_to != mutant_from:\n",
        "            new_sequence = copy.deepcopy(raw_sequence)\n",
        "            new_sequence[0][position] = aa1_to_index[mutant_to]\n",
        "            experiment_value.append(exp_value)\n",
        "            log_P_of_mt = baseline.get_P_of_seqs(new_sequence)\n",
        "            predicted_value.append(-(log_P_of_wt - log_P_of_mt))"
      ],
      "metadata": {
        "id": "HflmygMaBCj9"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "spearmanr(experiment_value, predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opG_8t8fHreW",
        "outputId": "6823d57f-e750-4ffe-de9b-d828e0f7a403"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.6061777186788756, pvalue=0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weighted result"
      ],
      "metadata": {
        "id": "wYGUtkooiwSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_weighted = torch.utils.data.DataLoader(dataset, batch_size=16, sampler=torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples=len(dataset)))"
      ],
      "metadata": {
        "id": "A_g7n4IVS93_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighed_seqs=[]\n",
        "for i in dataloader_weighted:\n",
        "  weighed_seqs.append(i[0][0].cpu().detach().numpy())\n",
        "weighed_seqs = np.array(weighed_seqs)"
      ],
      "metadata": {
        "id": "_tom2FHtbU9j"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_weighted = base1ine(pseudo_count=1)\n",
        "baseline_weighted.get_freqs(weighed_seqs)"
      ],
      "metadata": {
        "id": "dnNRI0PYhoP8"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "raw_sequence = [seqs[0]]\n",
        "log_P_of_wt = baseline_weighted.get_P_of_seqs(raw_sequence)\n",
        "experiment_value = []\n",
        "predicted_value = []\n",
        "for (position, mutant_from), row in experimental_data.iterrows():\n",
        "    assert aa1_to_index[mutant_from] == raw_sequence[0][position]\n",
        "    for mutant_to, exp_value in row.iteritems():\n",
        "        if mutant_to != mutant_from:\n",
        "            new_sequence = copy.deepcopy(raw_sequence)\n",
        "            new_sequence[0][position] = aa1_to_index[mutant_to]\n",
        "            experiment_value.append(exp_value)\n",
        "            log_P_of_mt = baseline_weighted.get_P_of_seqs(new_sequence)\n",
        "            predicted_value.append(-(log_P_of_wt - log_P_of_mt))"
      ],
      "metadata": {
        "id": "JzU9DwCHcnjB"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "spearmanr(experiment_value, predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9omd-30crue",
        "outputId": "510cd583-7060-4537-8883-c59a108d87aa"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.5960609586606334, pvalue=0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}