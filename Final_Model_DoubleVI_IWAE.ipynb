{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Final-Model-DoubleVI-IWAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PML Project\n",
        "\n",
        "Data: 2022-01-15\n",
        "\n",
        "Author: Jiajun He\n",
        "\n",
        "Content: IWAE DeepSequence"
      ],
      "metadata": {
        "id": "zwF5WzjgxvFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_1_b0.5_labeled.fasta"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:05.916931Z",
          "iopub.execute_input": "2022-01-08T21:44:05.917260Z",
          "iopub.status.idle": "2022-01-08T21:44:07.479169Z",
          "shell.execute_reply.started": "2022-01-08T21:44:05.917222Z",
          "shell.execute_reply": "2022-01-08T21:44:07.478358Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjQYAUdJxvFN",
        "outputId": "b05cc64c-1a76-44b1-fe14-a93f1c5fb4b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-17 06:12:23--  https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_1_b0.5_labeled.fasta\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2441075 (2.3M)\n",
            "Saving to: ‘BLAT_ECOLX_1_b0.5_labeled.fasta’\n",
            "\n",
            "BLAT_ECOLX_1_b0.5_l 100%[===================>]   2.33M  3.05MB/s    in 0.8s    \n",
            "\n",
            "2022-01-17 06:12:24 (3.05 MB/s) - ‘BLAT_ECOLX_1_b0.5_labeled.fasta’ saved [2441075/2441075]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhJvBmGuxxgs",
        "outputId": "da966ed2-03eb-4a9f-bad2-9e1a62cf7bda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing the FASTA file, codes from https://colab.research.google.com/github/wouterboomsma/pml_vae_project/blob/main/protein_vae_data_processing.ipynb\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "# FASTA parser requires Biopython\n",
        "try:\n",
        "    from Bio import SeqIO\n",
        "except:\n",
        "    !pip install biopython\n",
        "    from Bio import SeqIO\n",
        "    \n",
        "# Retrieve protein alignment file\n",
        "if not os.path.exists('BLAT_ECOLX_1_b0.5_labeled.fasta'):\n",
        "    !wget https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_1_b0.5_labeled.fasta\n",
        "        \n",
        "# Retrieve file with experimental measurements\n",
        "if not os.path.exists('BLAT_ECOLX_Ranganathan2015.csv'):\n",
        "    !wget https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_Ranganathan2015.csv\n",
        "        \n",
        "# Options\n",
        "batch_size = 16\n",
        "\n",
        "# Mapping from amino acids to integers\n",
        "aa1_to_index = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6,\n",
        "                'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12,\n",
        "                'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18,\n",
        "                'Y': 19, 'X':20, 'Z': 21, '-': 22}\n",
        "aa1 = \"ACDEFGHIKLMNPQRSTVWYXZ-\"\n",
        "\n",
        "phyla = ['Acidobacteria', 'Actinobacteria', 'Bacteroidetes',\n",
        "         'Chloroflexi', 'Cyanobacteria', 'Deinococcus-Thermus',\n",
        "         'Firmicutes', 'Fusobacteria', 'Proteobacteria', 'Other']\n",
        "\n",
        "def get_data(data_filename, calc_weights=False, weights_similarity_threshold=0.8):\n",
        "    '''Create dataset from FASTA filename'''\n",
        "    ids = []\n",
        "    labels = []\n",
        "    seqs = []\n",
        "    label_re = re.compile(r'\\[([^\\]]*)\\]')\n",
        "    for record in SeqIO.parse(data_filename, \"fasta\"):\n",
        "        ids.append(record.id)       \n",
        "        seqs.append(np.array([aa1_to_index[aa] for aa in str(record.seq).upper().replace('.', '-')]))\n",
        "        \n",
        "        label = label_re.search(record.description).group(1)\n",
        "        # Only use most common classes\n",
        "        if label not in phyla:\n",
        "            label = 'Other'\n",
        "        labels.append(label)\n",
        "                \n",
        "    seqs = torch.from_numpy(np.vstack(seqs))\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    phyla_lookup_table, phyla_idx = np.unique(labels, return_inverse=True)\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(*[seqs, torch.from_numpy(phyla_idx)])\n",
        "    \n",
        "    \n",
        "    weights = None\n",
        "    if calc_weights is not False:\n",
        "\n",
        "        # Experiencing memory issues on colab for this code because pytorch doesn't\n",
        "        # allow one_hot directly to bool. Splitting in two and then merging.\n",
        "        # one_hot = F.one_hot(seqs.long()).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        one_hot1 = F.one_hot(seqs[:len(seqs)//2].long()).bool()\n",
        "        one_hot2 = F.one_hot(seqs[len(seqs)//2:].long()).bool()\n",
        "        one_hot = torch.cat([one_hot1, one_hot2]).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        assert(len(seqs) == len(one_hot))\n",
        "        del one_hot1\n",
        "        del one_hot2\n",
        "        one_hot[seqs>19] = 0\n",
        "        flat_one_hot = one_hot.flatten(1)\n",
        "\n",
        "        weights = []\n",
        "        weight_batch_size = 1000\n",
        "        flat_one_hot = flat_one_hot.float()\n",
        "        for i in range(seqs.size(0) // weight_batch_size + 1):\n",
        "            x = flat_one_hot[i * weight_batch_size : (i + 1) * weight_batch_size]\n",
        "            similarities = torch.mm(x, flat_one_hot.T)\n",
        "            lengths = (seqs[i * weight_batch_size : (i + 1) * weight_batch_size] <=19).sum(1).unsqueeze(-1).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            w = 1.0 / (similarities / lengths).gt(weights_similarity_threshold).sum(1).float()\n",
        "            weights.append(w)\n",
        "            \n",
        "        weights = torch.cat(weights)\n",
        "        neff = weights.sum()\n",
        "\n",
        "    return dataset, weights\n",
        "\n",
        "\n",
        "dataset, weights = get_data('BLAT_ECOLX_1_b0.5_labeled.fasta', calc_weights=True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "dataloader_weighted = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples=len(dataset)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:07.481640Z",
          "iopub.execute_input": "2022-01-08T21:44:07.482220Z",
          "iopub.status.idle": "2022-01-08T21:44:08.635843Z",
          "shell.execute_reply.started": "2022-01-08T21:44:07.482154Z",
          "shell.execute_reply": "2022-01-08T21:44:08.634987Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBLMaRI2xvFO",
        "outputId": "060f88e9-ce7d-45cd-9378-eb47b5c09c8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n",
            "--2022-01-18 10:07:07--  https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_1_b0.5_labeled.fasta\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2441075 (2.3M)\n",
            "Saving to: ‘BLAT_ECOLX_1_b0.5_labeled.fasta’\n",
            "\n",
            "BLAT_ECOLX_1_b0.5_l 100%[===================>]   2.33M  1.24MB/s    in 1.9s    \n",
            "\n",
            "2022-01-18 10:07:11 (1.24 MB/s) - ‘BLAT_ECOLX_1_b0.5_labeled.fasta’ saved [2441075/2441075]\n",
            "\n",
            "--2022-01-18 10:07:11--  https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_Ranganathan2015.csv\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1216640 (1.2M) [text/csv]\n",
            "Saving to: ‘BLAT_ECOLX_Ranganathan2015.csv’\n",
            "\n",
            "BLAT_ECOLX_Ranganat 100%[===================>]   1.16M   263KB/s    in 4.5s    \n",
            "\n",
            "2022-01-18 10:07:18 (263 KB/s) - ‘BLAT_ECOLX_Ranganathan2015.csv’ saved [1216640/1216640]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import spearmanr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:08.637288Z",
          "iopub.execute_input": "2022-01-08T21:44:08.637561Z",
          "iopub.status.idle": "2022-01-08T21:44:08.641991Z",
          "shell.execute_reply.started": "2022-01-08T21:44:08.637524Z",
          "shell.execute_reply": "2022-01-08T21:44:08.641228Z"
        },
        "trusted": true,
        "id": "bY5SlBiNxvFQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global H\n",
        "H = 2000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:08.644347Z",
          "iopub.execute_input": "2022-01-08T21:44:08.644846Z",
          "iopub.status.idle": "2022-01-08T21:44:08.653562Z",
          "shell.execute_reply.started": "2022-01-08T21:44:08.644796Z",
          "shell.execute_reply": "2022-01-08T21:44:08.652717Z"
        },
        "trusted": true,
        "id": "oiflL_jwxvFQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepSeq_Double(nn.Module):\n",
        "    def __init__(self, input_size, latent_size, device):\n",
        "        super().__init__()\n",
        "        self.fc11 = nn.Linear(input_size, 1500) # 1500 is the number in the papar\n",
        "        self.fc12 = nn.Linear(1500, 1500)\n",
        "        self.fc131 = nn.Linear(1500, latent_size)\n",
        "        self.fc132 = nn.Linear(1500, latent_size)\n",
        "\n",
        "        self.fc21 = nn.Linear(latent_size, 100)\n",
        "        self.fc22 = nn.Linear(100, H)\n",
        "        \n",
        "\n",
        "        self.lambd_tilde_loc = nn.Parameter(torch.tensor(0.))\n",
        "        self.C_loc = nn.Parameter(torch.randn(23, 40))\n",
        "        self.W_tilde_loc = nn.Parameter(torch.randn(input_size//23, 40, H)) # L * E * H\n",
        "        self.S_tilde_loc = nn.Parameter(torch.randn(H//4, input_size//23) * 4 - 12)\n",
        "\n",
        "        self._lambd_tilde_scale = nn.Parameter(torch.tensor(0.) - 4)\n",
        "        self._C_scale = nn.Parameter(torch.zeros(23, 40) - 4)\n",
        "        self._W_tilde_scale = nn.Parameter(torch.zeros(input_size//23, 40, H) - 4) # L * E * H\n",
        "        self._S_tilde_scale = nn.Parameter(torch.zeros(H//4, input_size//23) - 4) # \n",
        "        \n",
        "        self.b3 = nn.Parameter(torch.randn(input_size//23, 23))\n",
        "\n",
        "        self.device = device\n",
        "    \n",
        "    def encoder(self, x):\n",
        "        x = nn.functional.one_hot(x, num_classes=23).float().reshape(x.shape[0], -1)\n",
        "        hidden = nn.ReLU()(self.fc11(x))\n",
        "        hidden = nn.ReLU()(self.fc12(hidden))\n",
        "        z_mu = self.fc131(hidden)\n",
        "        z_sd = torch.exp(self.fc132(hidden))\n",
        "\n",
        "        return z_mu, z_sd\n",
        "\n",
        "    def decoder(self, z, sample=True, lambd_tilde=None, C=None, S_tilde=None, W_tilde=None):\n",
        "        hidden = nn.ReLU()(self.fc21(z))\n",
        "        hidden = nn.Sigmoid()(self.fc22(hidden)) \n",
        "\n",
        "        # lambd_tilde = self.lambd_tilde_loc + nn.Softplus()(self._lambd_tilde_scale) * torch.randn_like(self.lambd_tilde_loc)\n",
        "        # C = self.C_loc + nn.Softplus()(self._C_scale) * torch.randn_like(self.C_loc)\n",
        "        # S_tilde = self.S_tilde_loc + nn.Softplus()(self._S_tilde_scale) * torch.randn_like(self.S_tilde_loc)\n",
        "        # W_tilde = self.W_tilde_loc + nn.Softplus()(self._W_tilde_scale) * torch.randn_like(self.W_tilde_loc)\n",
        "        if not sample:\n",
        "            lambd_tilde = self.lambd_tilde_loc\n",
        "            C = self.C_loc\n",
        "            S_tilde = self.S_tilde_loc\n",
        "            W_tilde = self.W_tilde_loc\n",
        "\n",
        "        S = torch.cat([1 / (torch.exp(-S_tilde.clone()) + 1) for i in range(4)], dim=0)\n",
        "        hidden = hidden[:, :, np.newaxis].expand([z.shape[0], H, S.shape[-1]])\n",
        "        Sh = torch.permute((hidden * S), (0, 2, 1))[:, :, :,np.newaxis] # B * L * H * 1\n",
        "        hidden = torch.log(torch.exp(lambd_tilde) + 1) * C @ W_tilde @ Sh #B L q 1\n",
        "        hidden = hidden[:, :, :, 0] + self.b3 #B * L * q\n",
        "\n",
        "        return hidden\n",
        "\n",
        "    # def forward(self, x, mc_samples=1, ann_factor=1., sample_params=True, calculate_global_KL=True):\n",
        "    #     z_mu, z_sd = self.encoder(x)\n",
        "\n",
        "    #     # prior distribution\n",
        "    #     prior = torch.distributions.Normal(0., 1.)\n",
        "    #     posterior = torch.distributions.Normal(z_mu, z_sd)\n",
        "\n",
        "    #     # since both prior and posterior are diag-Gaussian, the KL divergence between q(z|x) and p(z) is just the sum of the KL divergence in each dimension\n",
        "    #     KL_post_prior = torch.sum(torch.distributions.kl.kl_divergence(posterior, prior), dim=-1)\n",
        "\n",
        "    #     # E_q[p(x|z)] (sum because p(x|z) = p(x1|z)p(x2|z)...)\n",
        "    #     z = torch.randn_like(z_mu) * z_sd + z_mu\n",
        "    #     x_logit = self.decoder(z, sample_params)\n",
        "    #     Ep = torch.sum(torch.distributions.Categorical(logits=x_logit).log_prob(x), dim=-1)\n",
        "    #     for sample in range(mc_samples-1):\n",
        "    #         z = torch.randn_like(z_mu) * z_sd + z_mu\n",
        "    #         x_logit = self.decoder(z, sample_params)\n",
        "    #         Ep += torch.sum(torch.distributions.Categorical(logits=x_logit).log_prob(x), dim=-1)\n",
        "    #     Ep = Ep / mc_samples\n",
        "\n",
        "    #     ELBO = torch.sum(Ep - KL_post_prior)\n",
        "        \n",
        "    #     if calculate_global_KL:\n",
        "    #         # lambda distribution\n",
        "    #         prior_lambd_tilde = torch.distributions.Normal(0., 1.)\n",
        "    #         posterior_lambda_tilde = torch.distributions.Normal(self.lambd_tilde_loc, nn.Softplus()(self._lambd_tilde_scale))\n",
        "    #         KL_lambda_tilde = torch.sum(torch.distributions.kl.kl_divergence(posterior_lambda_tilde, prior_lambd_tilde))\n",
        "            \n",
        "    #         # C distribution\n",
        "    #         prior_C = torch.distributions.Normal(0., 1.)\n",
        "    #         posterior_C= torch.distributions.Normal(self.C_loc, nn.Softplus()(self._C_scale))\n",
        "    #         KL_C = torch.sum(torch.distributions.kl.kl_divergence(posterior_C, prior_C))\n",
        "            \n",
        "    #         # W distribution\n",
        "    #         prior_W_tilde = torch.distributions.Normal(0., 1.)\n",
        "    #         posterior_W_tilde = torch.distributions.Normal(self.W_tilde_loc, nn.Softplus()(self._W_tilde_scale))\n",
        "    #         KL_W_tilde = torch.sum(torch.distributions.kl.kl_divergence(posterior_W_tilde, prior_W_tilde))\n",
        "            \n",
        "    #         # S distribution\n",
        "    #         prior_S_tilde = torch.distributions.Normal(-12.36, 4.)\n",
        "    #         posterior_S_tilde = torch.distributions.Normal(self.S_tilde_loc, nn.Softplus()(self._S_tilde_scale))\n",
        "    #         KL_S_tilde = torch.sum(torch.distributions.kl.kl_divergence(posterior_S_tilde, prior_S_tilde))\n",
        "            \n",
        "    #         ELBO = ELBO - (KL_lambda_tilde + KL_C + KL_W_tilde + KL_S_tilde) * ann_factor\n",
        "        \n",
        "\n",
        "    #     return ELBO, z_mu, z_sd\n",
        "    # def forward_realIWAE(self, x, mc_samples_l=1, mc_samples_k=10, calculate_global_KL=True):\n",
        "\n",
        "    #     z_mu, z_sd = self.encoder(x)\n",
        "        \n",
        "    #     # z distribution\n",
        "    #     prior = torch.distributions.Normal(0., 1.)\n",
        "    #     posterior = torch.distributions.Normal(z_mu, z_sd)\n",
        "\n",
        "    #     # lambda distribution\n",
        "    #     prior_lambd_tilde = torch.distributions.Normal(0., 1.)\n",
        "    #     posterior_lambda_tilde = torch.distributions.Normal(self.lambd_tilde_loc, nn.Softplus()(self._lambd_tilde_scale))\n",
        "        \n",
        "    #     # C distribution\n",
        "    #     prior_C = torch.distributions.Normal(0., 1.)\n",
        "    #     posterior_C= torch.distributions.Normal(self.C_loc, nn.Softplus()(self._C_scale))\n",
        "        \n",
        "    #     # W distribution\n",
        "    #     prior_W_tilde = torch.distributions.Normal(0., 1.)\n",
        "    #     posterior_W_tilde = torch.distributions.Normal(self.W_tilde_loc, nn.Softplus()(self._W_tilde_scale))\n",
        "        \n",
        "    #     # S distribution\n",
        "    #     prior_S_tilde = torch.distributions.Normal(-12.36, 4.)\n",
        "    #     posterior_S_tilde = torch.distributions.Normal(self.S_tilde_loc, nn.Softplus()(self._S_tilde_scale))\n",
        "        \n",
        "\n",
        "    #     LOG_Ps = []\n",
        "    #     for s in range(mc_samples_l):\n",
        "    #         log_p = []\n",
        "    #         for sample in range(mc_samples_k):\n",
        "    #             z = torch.randn_like(z_mu) * z_sd + z_mu\n",
        "                \n",
        "    #             lambd_tilde = self.lambd_tilde_loc + nn.Softplus()(self._lambd_tilde_scale) * torch.randn_like(self.lambd_tilde_loc)\n",
        "    #             C = self.C_loc + nn.Softplus()(self._C_scale) * torch.randn_like(self.C_loc)\n",
        "    #             S_tilde = self.S_tilde_loc + nn.Softplus()(self._S_tilde_scale) * torch.randn_like(self.S_tilde_loc)\n",
        "    #             W_tilde = self.W_tilde_loc + nn.Softplus()(self._W_tilde_scale) * torch.randn_like(self.W_tilde_loc)\n",
        "\n",
        "    #             x_logit = self.decoder(z, sample=True, lambd_tilde=lambd_tilde, C=C, S_tilde=S_tilde, W_tilde=W_tilde)\n",
        "    #             log_p.append(\n",
        "    #                 torch.sum(torch.distributions.Categorical(logits=x_logit).log_prob(x), dim=-1, keepdim=True) + \\\n",
        "    #                 torch.sum(prior.log_prob(z) - posterior.log_prob(z), dim=-1, keepdim=True) + \\\n",
        "    #                 torch.sum(prior_lambd_tilde.log_prob(lambd_tilde) - posterior_lambda_tilde.log_prob(lambd_tilde)) - torch.log(torch.tensor(x.shape[0])) + \\\n",
        "    #                 torch.sum(prior_S_tilde.log_prob(S_tilde) - posterior_S_tilde.log_prob(S_tilde)) - torch.log(torch.tensor(x.shape[0])) + \\\n",
        "    #                 torch.sum(prior_W_tilde.log_prob(W_tilde) - posterior_W_tilde.log_prob(W_tilde)) - torch.log(torch.tensor(x.shape[0])) + \\\n",
        "    #                 torch.sum(prior_C.log_prob(C) - posterior_C.log_prob(C)) - torch.log(torch.tensor(x.shape[0]))\n",
        "    #                 ) # - torch.log(torch.tensor(x.shape[0])) because the KL of global variable will be broadcasted, we need to divide it by the batch size\n",
        "    #         log_p = torch.cat(log_p, dim=-1)\n",
        "\n",
        "    #         # To avoid numerical unstable\n",
        "    #         log_p_max = torch.max(log_p, dim=-1, keepdim=True)[0]\n",
        "    #         LOG_Ps.append(torch.log(torch.sum(torch.exp(log_p - log_p_max), dim=-1, keepdim=True) / mc_samples_k) + log_p_max)\n",
        "    #     LOG_Ps = torch.sum(torch.cat(LOG_Ps, dim=-1), dim=-1) / mc_samples_l\n",
        "        \n",
        "    #     L_IWAE = torch.sum(LOG_Ps)\n",
        "\n",
        "    #     return L_IWAE, z_mu, z_sd      \n",
        "    \n",
        "    def forward(self, x, mc_samples_l=1, mc_samples_k=10, calculate_global_KL=True):\n",
        "\n",
        "        z_mu, z_sd = self.encoder(x)\n",
        "        \n",
        "        # z distribution\n",
        "        prior = torch.distributions.Normal(0., 1.)\n",
        "        posterior = torch.distributions.Normal(z_mu, z_sd)\n",
        "\n",
        "        LOG_Ps = []\n",
        "        for s in range(mc_samples_l):\n",
        "            log_p = []\n",
        "            lambd_tilde = self.lambd_tilde_loc + nn.Softplus()(self._lambd_tilde_scale) * torch.randn_like(self.lambd_tilde_loc)\n",
        "            C = self.C_loc + nn.Softplus()(self._C_scale) * torch.randn_like(self.C_loc)\n",
        "            S_tilde = self.S_tilde_loc + nn.Softplus()(self._S_tilde_scale) * torch.randn_like(self.S_tilde_loc)\n",
        "            W_tilde = self.W_tilde_loc + nn.Softplus()(self._W_tilde_scale) * torch.randn_like(self.W_tilde_loc)\n",
        "            for sample in range(mc_samples_k):\n",
        "                z = torch.randn_like(z_mu) * z_sd + z_mu\n",
        "                x_logit = self.decoder(z, sample=True, lambd_tilde=lambd_tilde, C=C, S_tilde=S_tilde, W_tilde=W_tilde)\n",
        "                log_p.append(\n",
        "                    torch.sum(torch.distributions.Categorical(logits=x_logit).log_prob(x), dim=-1, keepdim=True) + \\\n",
        "                    torch.sum(prior.log_prob(z) - posterior.log_prob(z), dim=-1, keepdim=True)\n",
        "                    ) \n",
        "            log_p = torch.cat(log_p, dim=-1)\n",
        "\n",
        "            # To avoid numerical unstable\n",
        "            log_p_max = torch.max(log_p, dim=-1, keepdim=True)[0]\n",
        "            LOG_Ps.append(torch.log(torch.sum(torch.exp(log_p - log_p_max), dim=-1, keepdim=True) / mc_samples_k) + log_p_max)\n",
        "        LOG_Ps = torch.sum(torch.cat(LOG_Ps, dim=-1), dim=-1) / mc_samples_l\n",
        "        \n",
        "        L_IWAE = torch.sum(LOG_Ps)\n",
        "\n",
        "        if calculate_global_KL:\n",
        "            # lambda distribution\n",
        "            prior_lambd_tilde = torch.distributions.Normal(0., 1.)\n",
        "            posterior_lambda_tilde = torch.distributions.Normal(self.lambd_tilde_loc, nn.Softplus()(self._lambd_tilde_scale))\n",
        "            KL_lambda_tilde = torch.sum(torch.distributions.kl.kl_divergence(posterior_lambda_tilde, prior_lambd_tilde))\n",
        "            \n",
        "            # C distribution\n",
        "            prior_C = torch.distributions.Normal(0., 1.)\n",
        "            posterior_C= torch.distributions.Normal(self.C_loc, nn.Softplus()(self._C_scale))\n",
        "            KL_C = torch.sum(torch.distributions.kl.kl_divergence(posterior_C, prior_C))\n",
        "            \n",
        "            # W distribution\n",
        "            prior_W_tilde = torch.distributions.Normal(0., 1.)\n",
        "            posterior_W_tilde = torch.distributions.Normal(self.W_tilde_loc, nn.Softplus()(self._W_tilde_scale))\n",
        "            KL_W_tilde = torch.sum(torch.distributions.kl.kl_divergence(posterior_W_tilde, prior_W_tilde))\n",
        "            \n",
        "            # S distribution\n",
        "            prior_S_tilde = torch.distributions.Normal(-12.36, 4.)\n",
        "            posterior_S_tilde = torch.distributions.Normal(self.S_tilde_loc, nn.Softplus()(self._S_tilde_scale))\n",
        "            KL_S_tilde = torch.sum(torch.distributions.kl.kl_divergence(posterior_S_tilde, prior_S_tilde))\n",
        "            \n",
        "            L_IWAE = L_IWAE - (KL_lambda_tilde + KL_C + KL_W_tilde + KL_S_tilde)\n",
        "        \n",
        "        return L_IWAE, z_mu, z_sd\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:08.654952Z",
          "iopub.execute_input": "2022-01-08T21:44:08.655318Z",
          "iopub.status.idle": "2022-01-08T21:44:08.680357Z",
          "shell.execute_reply.started": "2022-01-08T21:44:08.655284Z",
          "shell.execute_reply": "2022-01-08T21:44:08.679664Z"
        },
        "trusted": true,
        "id": "A0HDr6hJxvFR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dl, optimizer, device):\n",
        "    ELBOs = []\n",
        "    for i in dl:\n",
        "        optimizer.zero_grad()\n",
        "        ELBO, _, _ = model(i[0].to(device), mc_samples_l=1, mc_samples_k=10)\n",
        "        loss = -ELBO\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        ELBOs.append(ELBO.item())\n",
        "    return sum(ELBOs) / len(ELBOs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:08.681407Z",
          "iopub.execute_input": "2022-01-08T21:44:08.681794Z",
          "iopub.status.idle": "2022-01-08T21:44:08.692790Z",
          "shell.execute_reply.started": "2022-01-08T21:44:08.681758Z",
          "shell.execute_reply": "2022-01-08T21:44:08.691800Z"
        },
        "trusted": true,
        "id": "URqM-9cNxvFS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = next(iter(dataloader))[0].shape[1] * 23\n",
        "DEVICE = \"cuda\"\n",
        "deepseq = DeepSeq_Double(input_size, 30, device=DEVICE).to(DEVICE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-08T21:44:08.693968Z",
          "iopub.execute_input": "2022-01-08T21:44:08.694299Z",
          "iopub.status.idle": "2022-01-08T21:44:09.029716Z",
          "shell.execute_reply.started": "2022-01-08T21:44:08.694261Z",
          "shell.execute_reply": "2022-01-08T21:44:09.028971Z"
        },
        "trusted": true,
        "id": "8XvzfzyVxvFS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "global_params = [id(deepseq.get_parameter(i)) for i in [\"_lambd_tilde_scale\", \"_C_scale\", \"_W_tilde_scale\", \"_S_tilde_scale\"]]\n",
        "base_params = filter(lambda p: id(p) not in global_params, deepseq.parameters())\n",
        "optimizer = Adam([{'params': base_params}, \n",
        "          {'params': [deepseq.state_dict()[i] for i in [\"_lambd_tilde_scale\", \"_C_scale\", \"_W_tilde_scale\", \"_S_tilde_scale\"]], 'lr': 1e-7}], \n",
        "          lr=4e-4)\n",
        "\n",
        "EPOCH = 201\n",
        "ELBOs = []\n",
        "for epoch in tqdm(range(EPOCH)):\n",
        "    if epoch % 10 == 0:\n",
        "        PATH = \"/content/drive/MyDrive/PML-project/FinalModel/\" + \"DoubleVI-IWAE-%d.pkl\"%epoch\n",
        "        torch.save(deepseq.state_dict(),PATH)\n",
        "\n",
        "        print(epoch, \":\")\n",
        "        # Check the reconstruct accuracy (make sure it learns normally)\n",
        "        acc = []\n",
        "        for i in range(len(dataset)):\n",
        "            raw_sequence = dataset[i][0][np.newaxis, :].to(DEVICE)\n",
        "            z_mu, _ = deepseq.encoder(raw_sequence)\n",
        "            acc.append(torch.argmax(deepseq.decoder(z_mu, False), dim=-1) == raw_sequence)\n",
        "        acc = np.mean(torch.cat(acc, dim=0).cpu().numpy())\n",
        "        print(\"Reconstruct Accuracy:\", acc)\n",
        "\n",
        "        raw_sequence = dataset[0][0][np.newaxis, :].to(DEVICE)\n",
        "        experiment_value = []\n",
        "        predicted_value = []\n",
        "        with torch.no_grad():\n",
        "            log_x_wt_ELBO, _, _ = deepseq(raw_sequence, 10, calculate_global_KL=False)\n",
        "            for (position, mutant_from), row in experimental_data.iterrows():\n",
        "                assert aa1_to_index[mutant_from] == raw_sequence[0, position]\n",
        "                for mutant_to, exp_value in row.iteritems():\n",
        "                    if mutant_to != mutant_from:\n",
        "                        new_sequence = raw_sequence.clone()\n",
        "                        new_sequence[0, position] = aa1_to_index[mutant_to]\n",
        "                        experiment_value.append(exp_value)\n",
        "                        log_x_mt_ELBO, _, _ = deepseq(new_sequence, 10, calculate_global_KL=False)\n",
        "                        predicted_value.append((log_x_mt_ELBO - log_x_wt_ELBO).item())\n",
        "        print(spearmanr(experiment_value, predicted_value))\n",
        "        \n",
        "\n",
        "    ELBOs.append(train(deepseq, dataloader_weighted, optimizer, DEVICE))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T00:51:36.371653Z",
          "iopub.execute_input": "2022-01-09T00:51:36.371925Z",
          "iopub.status.idle": "2022-01-09T01:14:47.799264Z",
          "shell.execute_reply.started": "2022-01-09T00:51:36.371895Z",
          "shell.execute_reply": "2022-01-09T01:14:47.798083Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzx1umcdxvFT",
        "outputId": "ce2282c5-c2c2-41b5-9da8-753730cb599f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/201 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 :\n",
            "Reconstruct Accuracy: 0.04430064974221657\n",
            "SpearmanrResult(correlation=-0.01223989736512748, pvalue=0.38701261127070485)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 10/201 [49:49<8:06:02, 152.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 :\n",
            "Reconstruct Accuracy: 0.587126727847009\n",
            "SpearmanrResult(correlation=0.6155575611658645, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 20/201 [1:39:39<7:40:27, 152.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 :\n",
            "Reconstruct Accuracy: 0.6191848459407108\n",
            "SpearmanrResult(correlation=0.6596583367604157, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 30/201 [2:29:28<7:14:35, 152.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 :\n",
            "Reconstruct Accuracy: 0.6385413859228336\n",
            "SpearmanrResult(correlation=0.6823821412658243, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 40/201 [3:19:19<6:49:32, 152.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 :\n",
            "Reconstruct Accuracy: 0.6572377133572341\n",
            "SpearmanrResult(correlation=0.6890700633266295, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 50/201 [4:09:11<6:23:58, 152.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 :\n",
            "Reconstruct Accuracy: 0.6666348355673272\n",
            "SpearmanrResult(correlation=0.6733190554617611, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 60/201 [4:59:11<5:59:53, 153.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60 :\n",
            "Reconstruct Accuracy: 0.6732481100082793\n",
            "SpearmanrResult(correlation=0.6925045110803982, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 70/201 [5:49:12<5:33:47, 152.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70 :\n",
            "Reconstruct Accuracy: 0.6805424407117499\n",
            "SpearmanrResult(correlation=0.6981726537581576, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 80/201 [6:39:10<5:08:02, 152.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80 :\n",
            "Reconstruct Accuracy: 0.6868600252451318\n",
            "SpearmanrResult(correlation=0.694470069196371, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 90/201 [7:29:02<4:42:24, 152.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90 :\n",
            "Reconstruct Accuracy: 0.6907655557128259\n",
            "SpearmanrResult(correlation=0.6972006827273134, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 100/201 [8:18:56<4:17:00, 152.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 :\n",
            "Reconstruct Accuracy: 0.6949604744998963\n",
            "SpearmanrResult(correlation=0.6944062502305448, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 110/201 [9:08:47<3:51:34, 152.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 :\n",
            "Reconstruct Accuracy: 0.6988281954384258\n",
            "SpearmanrResult(correlation=0.696524293578406, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 120/201 [9:58:39<3:25:57, 152.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120 :\n",
            "Reconstruct Accuracy: 0.7002794996732868\n",
            "SpearmanrResult(correlation=0.7032776054423837, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 130/201 [10:48:29<3:00:36, 152.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 :\n",
            "Reconstruct Accuracy: 0.7024918418669763\n",
            "SpearmanrResult(correlation=0.6876431937684752, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 140/201 [11:38:19<2:35:09, 152.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140 :\n",
            "Reconstruct Accuracy: 0.7043028213664557\n",
            "SpearmanrResult(correlation=0.6960253615865504, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 150/201 [12:28:21<2:10:22, 153.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 :\n",
            "Reconstruct Accuracy: 0.7073954469571084\n",
            "SpearmanrResult(correlation=0.6963093625593267, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 160/201 [13:18:25<1:44:42, 153.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160 :\n",
            "Reconstruct Accuracy: 0.7080546900297241\n",
            "SpearmanrResult(correlation=0.6951541992462055, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 170/201 [14:08:33<1:19:11, 153.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170 :\n",
            "Reconstruct Accuracy: 0.7095995486123903\n",
            "SpearmanrResult(correlation=0.6995613732107933, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 180/201 [14:58:36<53:33, 153.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180 :\n",
            "Reconstruct Accuracy: 0.7100842861657841\n",
            "SpearmanrResult(correlation=0.7007616145916438, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 190/201 [15:48:40<28:05, 153.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190 :\n",
            "Reconstruct Accuracy: 0.7113712643700447\n",
            "SpearmanrResult(correlation=0.6954939085152613, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 200/201 [16:38:48<02:33, 153.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 :\n",
            "Reconstruct Accuracy: 0.7121279396908926\n",
            "SpearmanrResult(correlation=0.7043106428675208, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 201/201 [17:09:16<00:00, 307.25s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 261\n",
        "for epoch in tqdm(range(201, EPOCH)):\n",
        "    if epoch % 10 == 0:\n",
        "        PATH = \"/content/drive/MyDrive/PML-project/FinalModel/\" + \"DoubleVI-IWAE-%d.pkl\"%epoch\n",
        "        torch.save(deepseq.state_dict(),PATH)\n",
        "\n",
        "        print(epoch, \":\")\n",
        "        # Check the reconstruct accuracy (make sure it learns normally)\n",
        "        acc = []\n",
        "        for i in range(len(dataset)):\n",
        "            raw_sequence = dataset[i][0][np.newaxis, :].to(DEVICE)\n",
        "            z_mu, _ = deepseq.encoder(raw_sequence)\n",
        "            acc.append(torch.argmax(deepseq.decoder(z_mu, False), dim=-1) == raw_sequence)\n",
        "        acc = np.mean(torch.cat(acc, dim=0).cpu().numpy())\n",
        "        print(\"Reconstruct Accuracy:\", acc)\n",
        "\n",
        "        raw_sequence = dataset[0][0][np.newaxis, :].to(DEVICE)\n",
        "        experiment_value = []\n",
        "        predicted_value = []\n",
        "        with torch.no_grad():\n",
        "            log_x_wt_ELBO, _, _ = deepseq(raw_sequence, 10, calculate_global_KL=False)\n",
        "            for (position, mutant_from), row in experimental_data.iterrows():\n",
        "                assert aa1_to_index[mutant_from] == raw_sequence[0, position]\n",
        "                for mutant_to, exp_value in row.iteritems():\n",
        "                    if mutant_to != mutant_from:\n",
        "                        new_sequence = raw_sequence.clone()\n",
        "                        new_sequence[0, position] = aa1_to_index[mutant_to]\n",
        "                        experiment_value.append(exp_value)\n",
        "                        log_x_mt_ELBO, _, _ = deepseq(new_sequence, 10, calculate_global_KL=False)\n",
        "                        predicted_value.append((log_x_mt_ELBO - log_x_wt_ELBO).item())\n",
        "        print(spearmanr(experiment_value, predicted_value))\n",
        "        \n",
        "\n",
        "    ELBOs.append(train(deepseq, dataloader_weighted, optimizer, DEVICE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPZW_1g_CW_i",
        "outputId": "a647e390-b57c-47da-c48d-3b878d386b83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 9/60 [19:55<1:52:48, 132.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210 :\n",
            "Reconstruct Accuracy: 0.7135128348809388\n",
            "SpearmanrResult(correlation=0.6987506692066767, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 19/60 [1:10:20<1:44:50, 153.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220 :\n",
            "Reconstruct Accuracy: 0.7149917691563433\n",
            "SpearmanrResult(correlation=0.6966625104972404, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 29/60 [2:00:41<1:19:16, 153.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230 :\n",
            "Reconstruct Accuracy: 0.7157872234814626\n",
            "SpearmanrResult(correlation=0.704826964215937, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 39/60 [2:50:42<53:40, 153.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240 :\n",
            "Reconstruct Accuracy: 0.7169767694374911\n",
            "SpearmanrResult(correlation=0.6949836911201619, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 49/60 [3:40:58<28:13, 153.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250 :\n",
            "Reconstruct Accuracy: 0.718972918682367\n",
            "SpearmanrResult(correlation=0.6979752224352139, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 59/60 [4:31:07<02:33, 153.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260 :\n",
            "Reconstruct Accuracy: 0.717826999106144\n",
            "SpearmanrResult(correlation=0.6975778061261392, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [5:01:32<00:00, 301.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/PML-project/FinalModel/\" + \"DoubleVI-IWAE-%d.pkl\"%230\n",
        "deepseq.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "F2DxFbvAx8R5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e7dd6f-42ae-43ca-e72a-d418e61a87f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the reconstruct accuracy (make sure it learns normally)\n",
        "acc = []\n",
        "for i in range(len(dataset)):\n",
        "    raw_sequence = dataset[i][0][np.newaxis, :].to(DEVICE)\n",
        "    z_mu, _ = deepseq.encoder(raw_sequence)\n",
        "    acc.append(torch.argmax(deepseq.decoder(z_mu, False), dim=-1) == raw_sequence)\n",
        "acc = np.mean(torch.cat(acc, dim=0).cpu().numpy())\n",
        "print(\"Reconstruct Accuracy:\", acc)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T01:14:55.607912Z",
          "iopub.execute_input": "2022-01-09T01:14:55.608566Z",
          "iopub.status.idle": "2022-01-09T01:15:18.781645Z",
          "shell.execute_reply.started": "2022-01-09T01:14:55.608532Z",
          "shell.execute_reply": "2022-01-09T01:15:18.780775Z"
        },
        "trusted": true,
        "id": "G8GD4GsxxvFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CJnSLk3HxvFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_Ranganathan2015.csv\n",
        "\n",
        "# Read in the experimental data, codes by Wooter from https://colab.research.google.com/github/wouterboomsma/pml_vae_project/blob/main/protein_vae_data_processing.ipynb\n",
        "\n",
        "def read_experimental_data(filename, alignment_data, measurement_col_name = '2500', sequence_offset=0):\n",
        "    '''Read experimental data from csv file, and check that amino acid match those \n",
        "       in the first sequence of the alignment.\n",
        "       \n",
        "       measurement_col_name specifies which column in the csv file contains the experimental \n",
        "       observation. In our case, this is the one called 2500.\n",
        "       \n",
        "       sequence_offset is used in case there is an overall offset between the\n",
        "       indices in the two files.\n",
        "       '''\n",
        "    \n",
        "    measurement_df = pd.read_csv(filename, delimiter=',', usecols=['mutant', measurement_col_name])\n",
        "    \n",
        "    wt_sequence, wt_label = alignment_data[0]\n",
        "    \n",
        "    zero_index = None\n",
        "    \n",
        "    experimental_data = {}\n",
        "    for idx, entry in measurement_df.iterrows():\n",
        "        mutant_from, position, mutant_to = entry['mutant'][:1],int(entry['mutant'][1:-1]),entry['mutant'][-1:]  \n",
        "        \n",
        "        # Use index of first entry as offset (keep track of this in case \n",
        "        # there are index gaps in experimental data)\n",
        "        if zero_index is None:\n",
        "            zero_index = position\n",
        "            \n",
        "        # Corresponding position in our alignment\n",
        "        seq_position = position-zero_index+sequence_offset\n",
        "            \n",
        "        # Make sure that two two inputs agree on the indices: the \n",
        "        # amino acids in the first entry of the alignment should be \n",
        "        # identical to those in the experimental file.\n",
        "        assert mutant_from == aa1[wt_sequence[seq_position]]  \n",
        "        \n",
        "        if seq_position not in experimental_data:\n",
        "            experimental_data[seq_position] = {}\n",
        "        \n",
        "        # Check that there is only a single experimental value for mutant\n",
        "        assert mutant_to not in experimental_data[seq_position]\n",
        "        \n",
        "        experimental_data[seq_position]['pos'] = seq_position\n",
        "        experimental_data[seq_position]['WT'] = mutant_from\n",
        "        experimental_data[seq_position][mutant_to] = entry[measurement_col_name]\n",
        "    \n",
        "    experimental_data = pd.DataFrame(experimental_data).transpose().set_index(['pos', 'WT'])\n",
        "    return experimental_data\n",
        "        \n",
        "        \n",
        "experimental_data = read_experimental_data(\"BLAT_ECOLX_Ranganathan2015.csv\", dataset)\n",
        "# For each of the entries in the dataframe above, you should calculate\n",
        "# the corresponding difference in ELBO from your VAE, and then finally\n",
        "# calculate a Spearman correlation between the two.\n",
        "\n",
        "# # You can iterate over all experimental values like this:\n",
        "# for (position, mutant_from), row in experimental_data.iterrows():\n",
        "#     print(position, mutant_from)   # mutant from is the wild type (wt)\n",
        "#     for mutant_to, exp_value in row.iteritems():\n",
        "#         print(\"\\t\", mutant_to, exp_value) "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T01:15:26.970256Z",
          "iopub.execute_input": "2022-01-09T01:15:26.970595Z",
          "iopub.status.idle": "2022-01-09T01:15:34.695535Z",
          "shell.execute_reply.started": "2022-01-09T01:15:26.970561Z",
          "shell.execute_reply": "2022-01-09T01:15:34.694565Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iANJeonxvFV",
        "outputId": "2bde80e1-cc80-4c49-c79b-19f709cf4f1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-18 10:07:39--  https://sid.erda.dk/share_redirect/a5PTfl88w0/BLAT_ECOLX_Ranganathan2015.csv\n",
            "Resolving sid.erda.dk (sid.erda.dk)... 130.225.104.13\n",
            "Connecting to sid.erda.dk (sid.erda.dk)|130.225.104.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1216640 (1.2M) [text/csv]\n",
            "Saving to: ‘BLAT_ECOLX_Ranganathan2015.csv.1’\n",
            "\n",
            "BLAT_ECOLX_Ranganat 100%[===================>]   1.16M   737KB/s    in 1.6s    \n",
            "\n",
            "2022-01-18 10:07:42 (737 KB/s) - ‘BLAT_ECOLX_Ranganathan2015.csv.1’ saved [1216640/1216640]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_sequence = dataset[0][0][np.newaxis, :].to(DEVICE)\n",
        "experiment_value = []\n",
        "predicted_value = []\n",
        "with torch.no_grad():\n",
        "    log_x_wt_ELBO, _, _ = deepseq(raw_sequence, 100, calculate_global_KL=False)\n",
        "    for (position, mutant_from), row in tqdm(experimental_data.iterrows()):\n",
        "        assert aa1_to_index[mutant_from] == raw_sequence[0, position]\n",
        "        for mutant_to, exp_value in row.iteritems():\n",
        "            if mutant_to != mutant_from:\n",
        "                new_sequence = raw_sequence.clone()\n",
        "                new_sequence[0, position] = aa1_to_index[mutant_to]\n",
        "                experiment_value.append(exp_value)\n",
        "                log_x_mt_ELBO, _, _ = deepseq(new_sequence, 100, calculate_global_KL=False)\n",
        "                predicted_value.append((log_x_mt_ELBO - log_x_wt_ELBO).item())\n",
        "print(spearmanr(experiment_value, predicted_value))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-09T01:16:25.428987Z",
          "iopub.execute_input": "2022-01-09T01:16:25.429629Z",
          "iopub.status.idle": "2022-01-09T01:18:52.332628Z",
          "shell.execute_reply.started": "2022-01-09T01:16:25.429586Z",
          "shell.execute_reply": "2022-01-09T01:18:52.331901Z"
        },
        "trusted": true,
        "id": "SEk6OIAVxvFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d50f62c-95de-42ea-8b74-961d9fba1e69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "263it [4:32:19, 62.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpearmanrResult(correlation=0.7243124956759219, pvalue=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y_kr3zDfBJzZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}